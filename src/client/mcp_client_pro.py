"""
MCPå®¢æˆ·ç«¯ä¸»æ¨¡å— - ä¼˜åŒ–ç‰ˆ
è´Ÿè´£ä¸MCPæœåŠ¡å™¨é€šä¿¡ï¼Œå¤„ç†ç”¨æˆ·æŸ¥è¯¢å’Œå·¥å…·è°ƒç”¨
"""
import sys
import os
import asyncio
import json
from typing import Optional, List, Dict, Any
from contextlib import AsyncExitStack
from pathlib import Path
from urllib.parse import quote_plus

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '../..'))

from openai import AsyncOpenAI
from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client

from config.settings import settings
from src.common.logger import get_logger
from src.common.exceptions import MCPClientError, APIError, ValidationError
from src.common.utils import (
    validate_json, 
    validate_tool_call, 
    sanitize_input,
    retry_with_backoff,
    timeout_wrapper,
    format_error_message
)
from src.common.prompts import prompt_manager, PromptType

logger = get_logger(__name__)


class MCPClient:
    """MCPå®¢æˆ·ç«¯ç±» - ä¼˜åŒ–ç‰ˆ"""
    
    def __init__(self):
        """åˆå§‹åŒ–MCPå®¢æˆ·ç«¯"""
        self.exit_stack = AsyncExitStack()
        self.session: Optional[ClientSession] = None
        self.stdio = None
        self.write = None
        
        # åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
        self.ai_client = AsyncOpenAI(
            base_url=settings.api.base_url,
            api_key=settings.api.api_key,
        )
        
        # è¿æ¥çŠ¶æ€
        self.is_connected = False
        logger.info("MCP Client initialized successfully")
    
    async def connect_to_server(self, server_script_path: str) -> None:
        """è¿æ¥åˆ°MCPæœåŠ¡å™¨"""
        try:
            logger.info(f"Connecting to MCP server: {server_script_path}")
            
            # éªŒè¯æœåŠ¡å™¨è„šæœ¬æ˜¯å¦å­˜åœ¨
            if not Path(server_script_path).exists():
                raise MCPClientError(f"Server script not found: {server_script_path}")
            
            # è®¾ç½®æœåŠ¡å™¨å‚æ•°
            server_params = StdioServerParameters(
                command="python",
                args=[server_script_path],
                env={"PYTHONUTF8": "1"}
            )
            
            # å»ºç«‹stdioè¿æ¥
            stdio_transport = await self.exit_stack.enter_async_context(
                stdio_client(server_params)
            )
            self.stdio, self.write = stdio_transport
            
            # åˆ›å»ºå®¢æˆ·ç«¯ä¼šè¯
            self.session = await self.exit_stack.enter_async_context(
                ClientSession(self.stdio, self.write)
            )
            
            # åˆå§‹åŒ–ä¼šè¯
            await self.session.initialize()
            self.is_connected = True
            logger.info("Successfully connected to server")
            
        except Exception as e:
            error_msg = format_error_message(e, "MCP server connection")
            logger.error(error_msg)
            raise MCPClientError(error_msg) from e

    def _validate_connection(self) -> None:
        """éªŒè¯è¿æ¥çŠ¶æ€"""
        if not self.is_connected or not self.session:
            raise MCPClientError("Not connected to MCP server. Please call connect_to_server() first.")
    
    @retry_with_backoff(max_retries=3, backoff_factor=1.0)
    async def _call_ai_model(self, messages: List[Dict[str, str]]) -> str:
        """è°ƒç”¨AIæ¨¡å‹"""
        try:
            response = await timeout_wrapper(
                self.ai_client.chat.completions.create(
                    model=settings.api.model,
                    messages=messages,
                    max_tokens=settings.model.max_tokens,
                    temperature=settings.model.temperature
                ),
                timeout_seconds=settings.api.timeout
            )
            
            content = response.choices[0].message.content
            print("----------------------------")
            print("content:", content)  # æ‰“å°contentä»¥æ£€æŸ¥å…¶å†…å®¹
            print("----------------------------")
            if not content:
                raise APIError("Empty response from AI model")
            
            return content
            
        except Exception as e:
            error_msg = format_error_message(e, "AI model call")
            logger.error(error_msg)
            raise APIError(error_msg) from e
    
    async def _call_mcp_tool(self, tool_name: str, tool_args: Dict[str, Any]) -> str:
        """è°ƒç”¨MCPå·¥å…·"""
        try:
            self._validate_connection()
            logger.info(f"Calling MCP tool: {tool_name} with args: {tool_args}")
            # tool_args_json = json.dumps(tool_args)
            result = await self.session.call_tool(tool_name, tool_args)
            
            if not result.content:
                raise MCPClientError(f"Empty result from tool: {tool_name}")
            
            tool_result = result.content[0].text
            logger.info(f"Tool {tool_name} executed successfully")
            return tool_result
            
        except Exception as e:
            error_msg = format_error_message(e, f"MCP tool call: {tool_name}")
            logger.error(error_msg)
            raise MCPClientError(error_msg) from e
    
    async def _get_available_tools(self) -> List[Dict[str, Any]]:
        """è·å–å¯ç”¨å·¥å…·åˆ—è¡¨"""
        try:
            self._validate_connection()
            response = await self.session.list_tools()
            tools = [
                {
                    "type": "function",
                    "function": {
                        "name": tool.name,
                        "description": tool.description,
                        "parameters": tool.inputSchema
                    }
                } for tool in response.tools
            ]
            logger.info(f"Available tools: {[t['function']['name'] for t in tools]}")
            return tools
        except Exception as e:
            error_msg = format_error_message(e, "get available tools")
            logger.error(error_msg)
            raise MCPClientError(error_msg) from e
    
    def _extract_json_from_text(self, text: str) -> tuple:
        """ä»æ–‡æœ¬ä¸­æå–JSONå†…å®¹"""
        if '```json' not in text:
            return False, text
        # æå–JSONå—å¹¶å»é™¤å‰åç©ºç™½å­—ç¬¦
        json_block = text.split('```json')[1].split('```')[0].strip()
        return True, json_block
    
    async def process_query(self, query: str) -> str:
        """å¤„ç†ç”¨æˆ·æŸ¥è¯¢ - ä¼˜åŒ–ç‰ˆ"""
        try:
            # éªŒè¯è¿æ¥å’Œè¾“å…¥
            self._validate_connection()
            query = sanitize_input(query)
            
            if not query:
                raise ValidationError("Query cannot be empty")
            
            logger.info(f"Processing query: {query[:100]}...")
            
            # è·å–å·¥å…·åˆ—è¡¨
            available_tools = await self._get_available_tools()
            
            # æ„å»ºç³»ç»Ÿæç¤ºè¯
            system_prompt = prompt_manager.get_prompt(
                PromptType.SYSTEM_ROUTER,
                tools=str(available_tools)
            )
            
            # æ„å»ºåˆå§‹æ¶ˆæ¯
            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": query}
            ]
            
            # è·å–AIæ¨¡å‹åˆå§‹å“åº”
            ai_response = await self._call_ai_model(messages)
            logger.info(f"Initial AI response: {ai_response[:200]}...")
            
            # å·¥å…·è°ƒç”¨ç»“æœæ”¶é›†
            tool_results = []
            max_iterations = 5
            current_iteration = 0
            
            while current_iteration < max_iterations:
                current_iteration += 1
                logger.info(f"Processing iteration {current_iteration}")
                
                # å°è¯•æå–JSONå†…å®¹
                is_json, content = self._extract_json_from_text(ai_response)
                
                if not is_json:
                    messages= [
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": query+"ï¼Œè¯·æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼š\n\n```json\n{\"name\": \"å·¥å…·åç§°\", \"params\": {\"å‚æ•°å\": \"å‚æ•°å€¼\"}}\n```\n\nç¡®ä¿è¾“å‡ºçš„æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼ã€‚"}
                    ]
                    ai_response = await self._call_ai_model(messages)
                    logger.info("No tool call detected, re-prompting AI for JSON output.")
                    continue # Continue the loop to re-evaluate the new ai_response
                
                # è§£æå’ŒéªŒè¯å·¥å…·è°ƒç”¨
                tool_data = json.loads(content)
                
                # æ‰§è¡Œå·¥å…·è°ƒç”¨
                tool_name = tool_data['name']
                tool_args = tool_data['params']

                # ç‰¹æ®Šå¤„ç†VL_modeå·¥å…·ï¼Œå°†urlåˆå¹¶åˆ°queryä¸­
                if tool_name == "VL_mode" and "url" in tool_args:
                    original_query = tool_args.get("query", "")
                    image_url = tool_args.pop("url") # ç§»é™¤urlé”®
                    tool_args["query"] = f"{original_query} {image_url}"
                
                try:
                    tool_result = await self._call_mcp_tool(tool_name, tool_args)
                    tool_results.append(tool_result)
                    
                    # æ›´æ–°æ¶ˆæ¯å†å²
                    messages.append({"role": "assistant", "content": ai_response})
                    messages.append({"role": "user", "content": f"å·¥å…·è°ƒç”¨ç»“æœï¼š{tool_result}"})
                    
                    # æ·»åŠ ä¸‹ä¸€æ­¥æ“ä½œæç¤º
                    next_step_prompt = prompt_manager.get_prompt(PromptType.NEXT_STEP, query=query)
                    messages.append({"role": "user", "content": next_step_prompt})
                    
                    # è·å–ä¸‹ä¸€æ­¥å†³ç­–
                    ai_response = await self._call_ai_model(messages)
                    logger.info(f"Next step response: {ai_response}")
                    
                    # æ£€æŸ¥æ˜¯å¦å®Œæˆ
                    if '<finish>' in ai_response.lower():
                        logger.info("Task completion detected")
                        break
                    
                except Exception as e:
                    logger.error(f"Tool execution failed: {e}")
                    # æ·»åŠ é”™è¯¯ä¿¡æ¯åˆ°æ¶ˆæ¯å†å²
                    error_msg = f"å·¥å…·è°ƒç”¨å¤±è´¥: {format_error_message(e, tool_name)}"
                    messages.append({"role": "user", "content": error_msg})
                    # ç»§ç»­å¤„ç†ä½†è·³è¿‡å½“å‰å·¥å…·
                    ai_response = await self._call_ai_model(messages)
            
            # ç”Ÿæˆæœ€ç»ˆç»“æœ
            if tool_results:
                final_prompt = prompt_manager.get_prompt(
                    PromptType.FINISH_GENERATE,
                    collected_info='\n\n'.join(tool_results),
                    query=query
                )
                messages.append({"role": "user", "content": final_prompt})
                final_response = await self._call_ai_model(messages)
                logger.info("Query processing completed successfully")
                return final_response
            else:
                logger.warning("No tool results collected")
                return "å¤„ç†å®Œæˆï¼Œä½†æœªè·å–åˆ°æœ‰æ•ˆç»“æœã€‚"
            
        except Exception as e:
            error_msg = format_error_message(e, "query processing")
            logger.error(error_msg)
            raise MCPClientError(error_msg) from e
    
    async def chat_loop(self) -> None:
        """å¯åŠ¨äº¤äº’å¼èŠå¤©å¾ªç¯ - ä¼˜åŒ–ç‰ˆ"""
        print("\nMCPæ™ºèƒ½è·¯ç”±åŠ©æ‰‹å·²å¯åŠ¨!")
        print("è¾“å…¥æ‚¨çš„é—®é¢˜æˆ–éœ€æ±‚ï¼Œè¾“å…¥ 'quit' é€€å‡ºç¨‹åº")
        print("-" * 50)
        
        while True:
            try:
                query = input("\nğŸ¤– è¯·è¾“å…¥æ‚¨çš„é—®é¢˜: ").strip()
                
                if query.lower() in ['quit', 'exit', 'é€€å‡º', 'q']:
                    print("æ„Ÿè°¢ä½¿ç”¨ï¼å†è§ï¼")
                    break
                
                if not query:
                    print("è¯·è¾“å…¥æœ‰æ•ˆçš„é—®é¢˜")
                    continue
                
                print("\nğŸ”„ æ­£åœ¨å¤„ç†æ‚¨çš„è¯·æ±‚...")
                response = await self.process_query(query)
                
                print("\n" + "="*60)
                print("ğŸ“‹ å¤„ç†ç»“æœ:")
                print("-" * 60)
                print(response)
                print("="*60)
                
            except KeyboardInterrupt:
                print("\n\nç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­ï¼Œæ­£åœ¨é€€å‡º...")
                break
            except Exception as e:
                error_msg = format_error_message(e, "chat loop")
                logger.error(error_msg)
                print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {error_msg}")
    
    async def cleanup(self) -> None:
        """æ¸…ç†èµ„æº"""
        try:
            if self.exit_stack:
                await self.exit_stack.aclose()
            self.is_connected = False
            logger.info("MCP Client cleanup completed")
        except Exception as e:
            logger.error(f"Cleanup error: {e}")


async def main():
    """ä¸»å‡½æ•° - ä¼˜åŒ–ç‰ˆ"""
    client = None
    try:
        client = MCPClient()
        server_path = os.path.join(os.path.dirname(__file__), '..', '..', 'src', 'server', 'mcp_server.py')
        await client.connect_to_server(server_path)
        await client.chat_loop()
    except Exception as e:
        error_msg = format_error_message(e, "main")
        logger.error(error_msg)
        print(f"å¯åŠ¨å¤±è´¥: {error_msg}")
    finally:
        if client:
            await client.cleanup()


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"ç¨‹åºå¼‚å¸¸é€€å‡º: {e}")